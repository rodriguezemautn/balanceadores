
### `# UTN FRLP - Laboratorios de Balanceo de Carga (SRE)`

Este repositorio contiene el entorno de pr谩ctica para la Sesi贸n de Balanceo de Carga, implementando y comparando algoritmos est谩ticos y din谩micos en **NGINX** y **HAProxy**.

### 1\. Configuraci贸n del Entorno

Aseg煤rese de haber completado los pasos de instalaci贸n de Docker en su VM de Rocky Linux.

**Clonar el Repositorio:**

```bash
git clone https://github.com/tu-usuario/lb-sre-labs.git 
cd lb-sre-labs
```

**Comandos Base:**

| Comando | Descripci贸n |
| :--- | :--- |
| `docker compose up -d` | Inicia todos los servicios (backends y balanceadores). |
| `docker compose down` | Detiene y elimina todos los contenedores. **Usar despu茅s de cada pr谩ctica.** |

### 2\. Backends de Aplicaci贸n

Todos los laboratorios usan tres servidores web (`web1`, `web2`, `web3`) que exponen el nombre del servidor para visualizar el balanceo.

  * **Contenido:** `backends/webN/index.html` (Muestra **`SERVER N`**).
  * **Servicio:** Definido en `docker-compose.yml`.

### 3\. Laboratorios con NGINX (Puerto 8080)

Para ejecutar cada laboratorio de NGINX, debe reemplazar el archivo de configuraci贸n activo:

```bash
# PASO 1: Reemplazar la configuraci贸n (ej: Round Robin)
sudo cp conf/nginx_rr.conf ./nginx.conf

# PASO 2: Reiniciar el contenedor NGINX para aplicar la nueva conf
docker compose restart nginx

# PASO 3: Ejecutar la prueba (usar el comando de prueba correspondiente)
```

#### И Lab 3.1: Round Robin (RR)

  * **Configuraci贸n:** `conf/nginx_rr.conf`
  * **Prueba (Verificaci贸n C铆clica):**

<!-- end list -->

```bash
watch -n 0.5 "curl -s localhost:8080 | grep SERVER"
# Verificaci贸n: El resultado debe ser 1 -> 2 -> 3 -> 1 -> ...
```

#### И Lab 3.2: Round Robin Ponderado (WRR)

  * **Configuraci贸n:** `conf/nginx_rr_ponderado.conf`
  * **Pesos:** `web1` (weight=3), `web2` (weight=1), `web3` (weight=1).
  * **Prueba (Verificaci贸n de Pesos):**

<!-- end list -->

```bash
watch -n 0.5 "curl -s localhost:8080 | grep SERVER"
# Verificaci贸n: De cada 5 peticiones, ~3 deben ir al SERVER 1.
```

#### И Lab 3.3: IP Hash (Afinidad de Sesi贸n)

  * **Configuraci贸n:** `conf/nginx_ip_hash.conf`
  * **Prueba (Simulaci贸n de IPs):**
    Utilizamos la cabecera `X-Forwarded-For` para simular diferentes IPs de cliente.

<!-- end list -->

```bash
echo "--- Prueba de Persistencia de Sesi贸n (Hash por IP) ---"
for ip in 1.1.1.1 8.8.8.8 4.4.4.4 1.1.1.1; do
  echo -n "$ip -> "
  curl -s --header "X-Forwarded-For: $ip" localhost:8080 | grep SERVER
done
# Verificaci贸n: El IP 1.1.1.1 debe ser enrutado al mismo SERVER cada vez.
```

#### И Lab 3.4: Least Connections (Concurrencia Din谩mica)

  * **Configuraci贸n:** `conf/nginx_least_conn.conf`
  * **Prueba (Simulaci贸n de Carga Pesada):**
    Usaremos `ab` (Apache Benchmark - si no est谩 instalado, `sudo dnf install httpd-tools -y`) para simular m煤ltiples conexiones.

<!-- end list -->

```bash
# PASO 1: Ejecutar 60 peticiones concurrentes (C=10)
# Esto estresar谩 el balanceador, haciendo que Least Connections redistribuya.
ab -n 60 -c 10 http://localhost:8080/

# PASO 2: Revisar los logs del balanceador (para ver la distribuci贸n)
docker compose logs nginx | grep "SERVER" 
# La distribuci贸n de solicitudes mostrar谩 que los servidores con menos carga activa recibieron m谩s solicitudes.
```

### 4\. Laboratorio con HAProxy (Puerto 8081)

**Nota:** HAProxy est谩 preconfigurado para usar el algoritmo Least Response Time.

#### И Lab 4.1: Least Response Time (Latencia Din谩mica)

  * **Configuraci贸n:** `conf/haproxy_least_resp.cfg`
  * **Prueba (Medici贸n de Latencia):**
    Simularemos que el `web3` es m谩s lento (agregando un *delay* de 1 segundo en su `index.html`).

<!-- end list -->

1.  **Hacer Lento el `web3` (Ejemplo avanzado):**

    ```bash
    # Agregar un delay de 1 segundo solo a web3 (para simular baja performance)
    echo '<p>SERVER 3 (DELAYED)</p>' > backends/web3/index.html
    docker compose restart web3
    ```

2.  **Prueba de Balanceo (Verificaci贸n de Distribuci贸n):**

    ```bash
    watch -n 0.5 "curl -s localhost:8081 | grep SERVER"
    # Verificaci贸n: HAProxy enviar谩 la mayor铆a del tr谩fico a web1 y web2, priorizando el menor tiempo de respuesta, hasta que la carga se iguale.
    ```

3.  **Restaurar `web3`:**

    ```bash
    echo '<p>SERVER 3 (WEB3)</p>' > backends/web3/index.html
    docker compose restart web3
    ```

### 5\. Finalizaci贸n del Laboratorio

**Recuerde siempre detener el entorno de contenedores al finalizar:**

```bash
docker compose down
```
